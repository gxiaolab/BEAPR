#include "Normalizer.h"

using namespace std;

void Normalizer::filterPKs(std::string r1_peak_fname, std::string r1_mp_fname, std::string input_mp_fname , std::string out_peak_fname,double input_size,double r1_size ,double cut){
	
  vector<string> bedvec = normalize_chr_new(r1_peak_fname , r1_mp_fname , input_mp_fname , input_size, r1_size, cut );
	
	tio.dlwrite(out_peak_fname, bedvec);
	
	string cmd = "rm -rf " + r1_peak_fname  ;
 // system(cmd.c_str());
}

void Normalizer::filterPKs(std::string r1_peak_fname, std::string out_peak_fname , double cut){
	
	vector<string> inVec =tio.dlread_vector(r1_peak_fname); 
	vector<string> outVec;
	
	for(int i =0 ; i<inVec.size() ; i++){
		vector<string> tokvec =  tok.Tokenize( inVec[i], "\t");
		double fc_rate = atof(tokvec[4].c_str());
		if(fc_rate> cut){
			outVec.push_back(inVec[i]);
		}
		else{
			//cout << "rm "<< inVec[i] << " < " << cut <<endl; 
		}
	}
	
	tio.dlwrite(out_peak_fname,outVec);

}


void Normalizer::normalize( std::string pkbed_fname, std::string input_fname,std::string r1_fname ,std::string tmp_dir ){
	
	//sep peaks by chrs  
	
	vector<string> PeaksVec = tio.dlread_vector(pkbed_fname);
	string old_chr = "";
	vector<string> tmpvec ;
	vector<string> chrvec;
	double r1_size,input_size ;
	
	for(int i =0 ; i<PeaksVec.size() ; i++){
		vector<string> tokvec = tok.Tokenize(PeaksVec[i], "\t");
				
		if(i==0){
			old_chr = tokvec[0];
		}
		
		if((tokvec[0]).compare(old_chr)!=0){
			//output 
				tio.dlwrite(tmp_dir+"/"+old_chr+"_pk.bed",tmpvec);
				chrvec.push_back(old_chr);	
				old_chr = tokvec[0]; 
				tmpvec.clear();
				
		}
		
		tmpvec.push_back(PeaksVec[i]);
		
	}
	tio.dlwrite(tmp_dir+"/"+old_chr+"_pk.bed",tmpvec);
	chrvec.push_back(old_chr);
	tmpvec.clear();
	PeaksVec.clear();
	
	
	//sep input by chrs
	
	vector<string> InputVec = tio.dlread_vector(input_fname);
	old_chr = "";
	input_size = (double) InputVec.size()/1000000.0;
	
	for(int i =0 ; i<InputVec.size() ; i++){
		vector<string> tokvec = tok.Tokenize(InputVec[i], "\t");
			
		if(i==0){
			old_chr = tokvec[2];
		}
		
		if((tokvec[2]).compare(old_chr)!=0){
			//output 
				tio.dlwrite(tmp_dir+"/"+old_chr+"_input.sam",tmpvec);
				
				old_chr = tokvec[2]; 
				tmpvec.clear();
		
		}
		
		tmpvec.push_back(InputVec[i]);
		
	}
	
	tio.dlwrite(tmp_dir+"/"+old_chr+"_input.sam",tmpvec);
	tmpvec.clear();
	InputVec.clear();
	
	//sep the r1 sample by chrs
	
	vector<string> RVec = tio.dlread_vector(r1_fname);
	old_chr = "";
	r1_size = (double)RVec.size()/1000000.0;
	for(int i =0 ; i<RVec.size() ; i++){
		vector<string> tokvec = tok.Tokenize(RVec[i], "\t");
				
		if(i==0){
			old_chr = tokvec[2];
		}
		
		if((tokvec[2]).compare(old_chr)!=0){
			//output 
				tio.dlwrite(tmp_dir+"/"+old_chr+"_r.sam",tmpvec);
				
				old_chr = tokvec[2]; 
				tmpvec.clear();
		
		}
		
		tmpvec.push_back(RVec[i]);
		
	}
	
	tio.dlwrite(tmp_dir+"/"+old_chr+"_r.sam",tmpvec);
	tmpvec.clear();
	RVec.clear();
	cout << "size:"<<input_size<< ","<< r1_size << endl;
	for( int i =0 ; i< 1/*chrvec.size()*/; i++){
		//cout << chrvec[i]<< endl;
		//normalize_chr(tmp_dir+"/"+chrvec[i]+"_pk.bed" ,tmp_dir+"/"+chrvec[i]+"_input.sam" ,tmp_dir+"/"+chrvec[i]+"_r.sam" , tmp_dir+"/"+chrvec[i]+".scale", input_size , r1_size);
	}
	
}

std::vector<std::string> Normalizer::normalize_chr_new( std::string pkbed_fname, std::string r1_fname, std::string input_fname, double input_size,double r1_size,double cut){
//	GenomeSegment gs;
	stringstream ss;
//	gs.initGenomeSegment_pksbed( pkbed_fname ,INT_MAX);
	//gs._debug();
	map<int , double > mp_input_map,mp_r1_map;
	map<string , string > bed_map;
	vector<string> outVec; 
	vector<string> BedVec = tio.dlread_vector(pkbed_fname);
	
	
	for(int i =0 ; i<BedVec.size() ; i++){
		vector<string> tokvec = tok.Tokenize(BedVec[i],"\t");
		string gname = tokvec[3];
				
		int exon_spos = atoi(tokvec[1].c_str())+1;
		int exon_epos = atoi(tokvec[2].c_str()); 
				
		ss.str("");
		ss<< exon_spos<< "_" <<exon_epos ;
		bed_map.insert(make_pair(ss.str(), BedVec[i]));
	}
	
	
	// calc input rc
	fstream filestr;
	filestr.open(input_fname.c_str(), ios_base::in);
		
	string str;	 
	while(!filestr.eof()){
	 	getline(filestr,str);
	 	if(str.length()>0){	 	
	 		vector<string> tokvec = tok.Tokenize(str , "\t"); 
			if(tokvec.size()>4){
				int mid_pt =  atoi(tokvec[1].c_str());
				string exon_str = ss.str();
				string baseStr = tokvec[4]; 
				double mp_depth = _depth(baseStr);
				mp_input_map.insert(make_pair( mid_pt, mp_depth )); 
				//cout <<"input@"<< mid_pt<<"," << mp_depth<< endl;			
			}
		}
	}
	filestr.close();
//	
	//calc r1 rc
	filestr.open(r1_fname.c_str(), ios_base::in);
		
	while(!filestr.eof()){
	 	getline(filestr,str);
	 	if(str.length()>0){	 	
	 		vector<string> tokvec = tok.Tokenize(str , "\t"); 
			if(tokvec.size()>4){
				int mid_pt =  atoi(tokvec[1].c_str());
				string exon_str = ss.str();
				string baseStr = tokvec[4];
				double mp_depth = _depth(baseStr);
				mp_r1_map.insert(make_pair( mid_pt, mp_depth ));
				//cout <<"r1@"<< mid_pt<<"," << mp_depth<< endl;				
			}
		}
	}
	filestr.close();

	for(map<string,string>::iterator m_itr = bed_map.begin(); m_itr != bed_map.end(); m_itr++){
		
		//cout << "calc :" <<  m_itr->first << endl;
		vector<string> tokvec = tok.Tokenize( m_itr->first,"_" );
		int a_pos = atoi(tokvec[0].c_str());
		int b_pos = atoi(tokvec[1].c_str());
		
		//cout << "from :" <<   a_pos << ","<< b_pos  << endl;
		double r1_depth =0;
		double input_depth =0;
		for(int j = a_pos ;j<=b_pos ; j++){
			if(mp_r1_map.find(j)!=mp_r1_map.end()){
				r1_depth = r1_depth + mp_r1_map[j];
				//cout << "r1@"<< j << " " << mp_r1_map[j] << endl;
			}
			if(mp_input_map.find(j)!=mp_input_map.end()){
				input_depth = input_depth + mp_input_map[j];
				//cout << "input@"<< j << " " << mp_input_map[j] << endl;
			}
		}
		
		
		double input_sg = input_depth/(double) input_size ;
		double r1_sg = r1_depth/(double) r1_size ;
		
		//outVec.push_back(ss.str());
		//cout << m_itr->second << " $ " << r1_depth  << " "<< input_depth <<" " <<    (r1_sg+0.1)  <<" " << (input_sg+0.1)<< endl;
		if(((r1_sg+0.1) / (input_sg+0.1)) > cut){
					
			outVec.push_back(m_itr->second);
		}
		
	}
	return outVec;
}

std::vector<std::string> Normalizer::normalize_chr( std::string pkbed_fname, std::string input_fname,std::string r1_fname, double input_size,double r1_size,double cut){
	GenomeSegment gs;
	stringstream ss;
	gs.initGenomeSegment_pksbed( pkbed_fname ,INT_MAX);
	//gs._debug();
	map<string , double > input_map,r1_map; 
	
	map<string , string > bed_map;
	vector<string> outVec; 
	vector<string> BedVec = tio.dlread_vector(pkbed_fname);
	
	
	for(int i =0 ; i<BedVec.size() ; i++){
		vector<string> tokvec = tok.Tokenize(BedVec[i],"\t");
		string gname = tokvec[3];
				
		int exon_spos = atoi(tokvec[1].c_str())+1;
		int exon_epos = atoi(tokvec[2].c_str()); 
				
		ss.str("");
		ss<< exon_spos<< "_" <<exon_epos ;
		bed_map.insert(make_pair(ss.str(), BedVec[i]));
	}
	
	//init exons map
	for(map<string, std::map<std::string, std::string> >::iterator m_itr = gs.ExonMap.begin() ; m_itr != gs.ExonMap.end() ; m_itr++){
		
	  r1_map.insert(make_pair(m_itr->first,0.0));
		input_map.insert(make_pair(m_itr->first,0.0));
	}
	
	
	// calc input rc
	fstream filestr;
	filestr.open(input_fname.c_str(), ios_base::in);
		
	string str;	 
	while(!filestr.eof()){
	 	getline(filestr,str);
	 	if(str.length()>0){	 	
	 		vector<string> tokvec = tok.Tokenize(str , "\t"); 
			if(tokvec.size()>4){
				int mid_pt =  atoi(tokvec[1].c_str());
				string seg_str = gs.find_interval(mid_pt) ;
				vector<string> tmpvec = tok.Tokenize(seg_str,"_"); 
				int a_idx = atoi(tmpvec[0].c_str());
				int b_idx = atoi(tmpvec[1].c_str());
				ss.str("");
				ss << gs.PosVec[a_idx] << "_"<< gs.PosVec[b_idx] ;

				if(input_map.find(ss.str()) != input_map.end() ){
					
					string exon_str = ss.str();
					string baseStr = tokvec[4]; 
					vector<string> baseVec = _sepBaseStr(baseStr);
					input_map[exon_str]= input_map[exon_str]+baseVec.size();
				}
			}
		}
	}
	filestr.close();
//	
	//calc r1 rc
	filestr.open(r1_fname.c_str(), ios_base::in);
		
	while(!filestr.eof()){
	 	getline(filestr,str);
	 	if(str.length()>0){	 	
	 		vector<string> tokvec = tok.Tokenize(str , "\t"); 
			if(tokvec.size()>4){
				int mid_pt =  atoi(tokvec[1].c_str());
				string seg_str = gs.find_interval(mid_pt) ;
				vector<string> tmpvec = tok.Tokenize(seg_str,"_"); 
				int a_idx = atoi(tmpvec[0].c_str());
				int b_idx = atoi(tmpvec[1].c_str());
				ss.str("");
				ss << gs.PosVec[a_idx] << "_"<< gs.PosVec[b_idx] ;
				if(r1_map.find(ss.str()) != r1_map.end() ){

					string exon_str = ss.str();
					string baseStr = tokvec[4]; 
					vector<string> baseVec = _sepBaseStr(baseStr);
					r1_map[exon_str]= r1_map[exon_str]+baseVec.size();
				}				
			}
		}
	}
	filestr.close();


//	
// 	vector<string> outVec;
// 	ss.str("");
// 	ss<< r1_size;
// 	outVec.push_back(ss.str());
	for(map<string,string>::iterator m_itr = bed_map.begin(); m_itr != bed_map.end(); m_itr++){
		ss.str("");
		ss << m_itr->first << "\t"<<input_map[m_itr->first] << "\t"<<r1_map[m_itr->first] ;
		double input_sg = input_map[m_itr->first]/(double) input_size ;
		double r1_sg = r1_map[m_itr->first]/(double) r1_size ;
		
		ss<< "\t"<<r1_sg / input_sg ; 
		//outVec.push_back(ss.str());
		if((r1_sg / input_sg) > cut){
			
			//cout << m_itr->second<< endl;
			outVec.push_back(m_itr->second);
		}
		
	}
//	
//	tio.dlwrite(outfname,outVec);
	return outVec;
}

std::vector<std::string>  Normalizer::_sepBaseStr(std::string baseStr){
	vector<string> outVec;
	stringstream ss;
	for(int i =0; i<baseStr.length(); ){
		int k=1;
		
		if(baseStr[i]=='.' || baseStr[i]==',' || baseStr[i]=='>' || baseStr[i]=='<'|| baseStr[i]=='A' || baseStr[i]=='a'|| baseStr[i]=='T' || baseStr[i]=='t'|| baseStr[i]=='C' || baseStr[i]=='c'|| baseStr[i]=='G' || baseStr[i]=='g' || baseStr[i]=='*'){
			ss.str("");
			ss<< baseStr[i];
			outVec.push_back(ss.str());
		}
		if(baseStr[i]=='^'){
			ss.str("");
			ss<< baseStr[i+2];
			outVec.push_back(ss.str());
			k=3;
		}
		if(baseStr[i]=='+' || baseStr[i]=='-'){
			ss.str("");
			int d_num=0;
			int str_len ;
			ss << baseStr[i];
			
			while(baseStr[i+1+d_num]>=48 && baseStr[i+1+d_num]<=57 ){
				ss << baseStr[i+1+d_num];
				d_num++;
			}
			
			string tmp_str = ss.str();
			
			tmp_str = tmp_str.substr(1);
			str_len = atoi(tmp_str.c_str()); 
			
			for(int j =1 ; j<=str_len; j++){
				ss<< baseStr[i+d_num+j];
			}
	
			k = d_num+ str_len+1;
		}
		
		i= i+k;
	}
	
	return outVec;
}


double  Normalizer::_depth(std::string baseStr){
	vector<string> outVec;
	stringstream ss;
	double outd= 0.0 ;
	for(int i =0; i<baseStr.length(); ){
		int k=1;
		
		if(baseStr[i]=='.' || baseStr[i]==',' || baseStr[i]=='A' || baseStr[i]=='a'|| baseStr[i]=='T' || baseStr[i]=='t'|| baseStr[i]=='C' || baseStr[i]=='c'|| baseStr[i]=='G' || baseStr[i]=='g' ){
			outd = outd +1.0;
		}
		if(baseStr[i]=='^'){
			outd = outd +1.0;
			k=3;
		}
		if(baseStr[i]=='+' || baseStr[i]=='-'){
			ss.str("");
			int d_num=0;
			int str_len ;
			ss << baseStr[i];
			
			while(baseStr[i+1+d_num]>=48 && baseStr[i+1+d_num]<=57 ){
				ss << baseStr[i+1+d_num];
				d_num++;
			}
			
			string tmp_str = ss.str();
			
			tmp_str = tmp_str.substr(1);
			str_len = atoi(tmp_str.c_str()); 
			
			for(int j =1 ; j<=str_len; j++){
				ss<< baseStr[i+d_num+j];
			}
	
			k = d_num+ str_len+1;
		}
		
		i= i+k;
	}
	
	return outd;
}

double  Normalizer::_match(std::string baseStr){
	vector<string> outVec;
	stringstream ss;
	double outd= 0.0 ;
	for(int i =0; i<baseStr.length(); i++){
	
		if(baseStr[i]=='.' || baseStr[i]==','  ){
			outd = outd +1.0;
		}
	
	}
	
	return outd;
}

int Normalizer::_mid_point(std::string sam_str){ //get the middle point of the reads
		stringstream ss,ss_cigar;
		int itr;
		vector<string> tokvec = tok.Tokenize(sam_str,"\t");
		string seq =  tokvec[9];
		string cigar = tokvec[5];
		string pos_str = tokvec[3];
		int offset_max = seq.length()/2;
		
		int current_idx = 1;
		int current_offset = 0;
		ss.str("");
		int flag =0;
		
		for(int i =0 ; i < cigar.length() ; i++){
				if( (int)(cigar[i]) <=57 && (int)(cigar[i])>=48 || cigar[i] == 'M' || cigar[i] == 'I' || cigar[i] == 'D' || cigar[i] == 'N'){
					//cout << "d:"<< cigar[i]<< endl;
				}
				else{
					flag =1;
				}
		}
		
		if(flag ==0){
			//convert cigar to full-cigar
			ss_cigar.str("");
			for(int i =0 ; i < cigar.length() ; i++){
				if( (int)(cigar[i]) <=57 && (int)(cigar[i])>=48){
					ss << cigar[i];
				}
				else{
					int rep_num = atoi((ss.str()).c_str());
					for( int j=0 ; j<rep_num; j++){
						ss_cigar<< cigar[i]; 
					}
					ss.str("");
				}
			}
			string full_cigar = ss_cigar.str(); 
			//count unitl the middle point is reached
			itr =0;
			while(current_offset <=offset_max ){
				if(full_cigar[itr]=='M' ){
					current_offset++;
					itr++;
				}
				if(full_cigar[itr]=='N' ||full_cigar[itr]=='D'){
					itr++;
				}
				if(full_cigar[itr]=='I' ){
					current_offset++;
				}
				
			}
			
		}
		
		return itr+atoi(pos_str.c_str())-1;
}


std::map< int, std::vector<double> > Normalizer::estimateSeqError( std::string mpfname, std::string SNPfname,double lib_size, int pos_flag ){
	
	map<string,string> SNPMap;
	map< int, vector<double> > outMap;
		
	fstream filestr;
  string str;
	stringstream ss;
	
	//init OutMap
	for(int i =0 ; i<10; i++ ){
		vector<double> tmpvec;
		for(int j =0 ; j<20; j++){
			tmpvec.push_back(0.0);
		}
		outMap.insert(make_pair( i, tmpvec ));
	}	
	//read SNPs 
	
	filestr.open(SNPfname.c_str(), ios_base::in);
	
	while(!filestr.eof()){
	 	getline(filestr,str);
	 	if(str.length()>0){	 	
			vector<string> tokvec = tok.Tokenize( str," ");					
			ss.str("");
			ss<< tokvec[0] << "_"<< tokvec[1] ;
			SNPMap.insert(make_pair(ss.str(),""));
		}
	}
	filestr.close();
	
	//cout <<SNPMap.size() << endl; 
	// collect mutations not on any SNP site
	
	filestr.open(mpfname.c_str(), ios_base::in);
	
		
	while(!filestr.eof()){
	 	getline(filestr,str);
	 	if(str.length()>0){	 	
			vector<string> tokvec = tok.Tokenize( str,"\t");					
			
			if(tokvec.size() > 4){
				ss.str("");
				ss<< tokvec[0] << "_"<< tokvec[1] ;
				string snp_id = ss.str();
				int rna_edit =0;
				int mut_flag =0;
				string p_str = tokvec[4]; 
				vector<string> basevec =  _sepBaseStr(p_str);
				for(int i =0 ; i<basevec.size() ; i++){
					if( basevec[i].compare("a")==0||basevec[i].compare("A")==0 || basevec[i].compare("t")==0||basevec[i].compare("T")==0 || basevec[i].compare("c")==0||basevec[i].compare("C")==0 || basevec[i].compare("g")==0||basevec[i].compare("G")==0) {
						mut_flag =1;
					}
					
					
				}
				
					
				if(mut_flag ==1){
			
					if(pos_flag ==1 ){ // ont the "+" strain 
					//chk if A to G or C to T
					if(tokvec[2].compare("a")==0 || tokvec[2].compare("A")==0){
						//scan G
						for(int p =0; p<basevec.size(); p ++){
							if(basevec[p].compare("g")== 0 || basevec[p].compare("g")== 0){
								rna_edit = 1;
							}
						}
					}
					
					if(tokvec[2].compare("c")==0 || tokvec[2].compare("C")==0){
						//scan T
						for(int p =0; p<basevec.size(); p ++){
							if(basevec[p].compare("t")== 0 || basevec[p].compare("T")== 0){
								rna_edit = 1;
							}
						}
					}
					}
					else{
					//chk if A to G or C to T
					if(tokvec[2].compare("t")==0 || tokvec[2].compare("T")==0){
						//scan C
						for(int p =0; p<basevec.size(); p ++){
							if(basevec[p].compare("c")== 0 || basevec[p].compare("C")== 0){
								rna_edit = 1;
							}
						}
					}
					if(tokvec[2].compare("g")==0 || tokvec[2].compare("G")==0){
						//scan A
						for(int p =0; p<basevec.size(); p ++){
							if(basevec[p].compare("a")== 0 || basevec[p].compare("A")== 0){
								rna_edit = 1;
							}
						}
					}
					}
				
//	
					if(SNPMap.find(snp_id) != SNPMap.end() ){
						cout << "@@SNP : "<< snp_id << "\t" <<p_str  << endl;
					}
					if(SNPMap.find(snp_id) == SNPMap.end() && rna_edit == 0){
						double depth = _depth(tokvec[4]); 
						double mut = depth - _match(tokvec[4]);
						double mut_rate = mut/depth;
					
					
						if(mut > 0 ){
							double mut_rate =  mut/(double) depth;
						
							int dep_idx= depth/10;
							if(dep_idx >9 ){
								dep_idx =9;
							}
							int mut_idx = mut_rate / 0.05;
							if(mut_idx >19){
								mut_idx =19;
							}
						
						  //cout << snp_id << "\t" <<p_str << "\t"<< mut << "\t" << depth <<  "\t"<< mut_rate << "\t"<< dep_idx << "\t" << mut_idx<< endl;
							
							outMap[dep_idx][mut_idx] = outMap[dep_idx][mut_idx] + 1.0 ;
						}
					}
				
				}
			
				
				
			}
		}
	}
	filestr.close();
	
//	for(int i =0 ; i< 10; i++){
//		for(int j =0 ; j<20; j++){
//			cout << outMap[i][j]<< ",";
//			
//		}
//		cout << endl;
//	}
	
	return  outMap;
}
